# Environment Variables Configuration

# Copy this file to .env and fill in your actual values
# Never commit .env files with real secrets to version control

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# MongoDB connection string
# Local development with Docker: mongodb://admin:password@localhost:27017/procureflow?authSource=admin
# Local development standalone: mongodb://localhost:27017/procureflow
# MongoDB Atlas: mongodb+srv://username:password@cluster.mongodb.net/procureflow
MONGODB_URI=mongodb://

# =============================================================================
# AUTHENTICATION CONFIGURATION (Auth.js / NextAuth.js)
# =============================================================================

# NextAuth.js secret key - MUST be changed in production
# Generate with: openssl rand -base64 32
NEXTAUTH_SECRET=your-secret-key-change-in-production

# Application URL - Update for production deployment
NEXTAUTH_URL=http://localhost:3000

# =============================================================================
# OAUTH PROVIDERS (Optional)
# =============================================================================

# Google OAuth Configuration
# Get these from: https://console.cloud.google.com/apis/credentials
# GOOGLE_CLIENT_ID=your-google-oauth-client-id
# GOOGLE_CLIENT_SECRET=your-google-oauth-client-secret

# GitHub OAuth Configuration (Future)
# GITHUB_CLIENT_ID=your-github-oauth-client-id
# GITHUB_CLIENT_SECRET=your-github-oauth-client-secret

# =============================================================================
# AI SERVICES CONFIGURATION
# =============================================================================

# AI Provider Selection (optional override)
# Options: openai, gemini
# If not set, auto-detects in priority order: OpenAI > Gemini
# AI_PROVIDER=openai

# OpenAI API Key for LangChain integration
# Get from: https://platform.openai.com/api-keys
# Required for AI features if not using Google Gemini
OPENAI_API_KEY=sk-proj-

# Google Gemini API Key (Alternative to OpenAI)
# Get from: https://aistudio.google.com/app/apikey
# Free tier available with generous limits
GOOGLE_API_KEY=

# OpenAI Content Moderation (optional)
# Enable to check user inputs for hate speech, violence, etc.
# Uses OpenAI Moderation API (requires OPENAI_API_KEY)
# OPENAI_MODERATION_ENABLED=true

# OpenAI Reliability Configuration
# Rate limit: Requests per minute (default: 60 for free tier)
# OPENAI_RPM_LIMIT=60
# Max retries on transient failures (default: 3)
# OPENAI_MAX_RETRIES=3
# Timeout in milliseconds (default: 30000 = 30s)
# OPENAI_TIMEOUT_MS=30000

# Gemini Reliability Configuration
# Rate limit: Requests per minute (default: 15 for free tier)
# GEMINI_RPM_LIMIT=15
# Max retries on transient failures (default: 4)
# GEMINI_MAX_RETRIES=4
# Timeout in milliseconds (default: 30000 = 30s)
# GEMINI_TIMEOUT_MS=30000

# Circuit Breaker Configuration (applies to all providers)
# Error threshold percentage to open circuit (default: 50)
# CIRCUIT_BREAKER_ERROR_THRESHOLD=50
# Reset timeout in milliseconds (default: 30000 = 30s)
# CIRCUIT_BREAKER_RESET_TIMEOUT=30000

# Optional: Override default OpenAI model
# OPENAI_MODEL=gpt-3.5-turbo

# Optional: Override default temperature (0.0 to 1.0)
# OPENAI_TEMPERATURE=0.7

# =============================================================================
# AGENT MEMORY CONFIGURATION
# =============================================================================

# Maximum number of history messages to include in agent context
# Prevents memory overflow in long conversations
# Default: 50 messages
# AGENT_MAX_HISTORY_MESSAGES=50

# Maximum tokens for input message history (budget allocation)
# Controls how much conversation history to include based on token count
# Default: 3000 tokens
# AGENT_MAX_INPUT_TOKENS=3000

# Absolute maximum tokens for total conversation context
# Fail-safe to prevent exceeding model context limits
# Includes system prompt, cart context, history, and user message
# Default: 4000 tokens
# AGENT_MAX_TOTAL_TOKENS=4000

# Enable conversation summarization (future feature)
# When enabled, old messages are summarized to preserve context
# AGENT_ENABLE_SUMMARIZATION=false

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================

# Node.js environment
NODE_ENV=development

# Application name and version (optional)
# APP_NAME=ProcureFlow
# APP_VERSION=0.1.0

# =============================================================================
# CLOUD INFRASTRUCTURE (Pulumi/GCP)
# =============================================================================

# Google Cloud Platform Project ID
# Required for Pulumi GCP deployment
# GCP_PROJECT_ID=your-gcp-project-id

# GCP Region
# GCP_REGION=us-central1

# GCP Zone
# GCP_ZONE=us-central1-a

# =============================================================================
# OPTIONAL SERVICES
# =============================================================================

# Redis for caching (Future implementation)
# REDIS_URL=redis://localhost:6379

# Email service configuration (Future implementation)
# EMAIL_SERVER=smtp://username:password@smtp.example.com:587
# EMAIL_FROM=noreply@procureflow.com

# File storage service (Future implementation)
# STORAGE_PROVIDER=local
# STORAGE_PATH=./uploads

# =============================================================================
# MONITORING AND OBSERVABILITY (Future implementation)
# =============================================================================

# LangSmith Tracing (LangChain observability platform)
# Get API key from: https://smith.langchain.com/
# Enable tracing to debug LLM calls, tool executions, and agent behavior
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=procureflow-dev

# Loki Log Aggregation (production)
# Grafana Loki endpoint for centralized logging
# Example: http://loki:3100
# LOKI_HOST=

# Logging Level
# Options: debug, info, warn, error
LOG_LEVEL=info

# Sentry DSN for error tracking
# SENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id

# Application Insights (if using Azure)
# APPLICATIONINSIGHTS_CONNECTION_STRING=your-connection-string

# =============================================================================
# DEVELOPMENT TOOLS
# =============================================================================

# Enable debug logging
# DEBUG=procureflow:*

# Disable Next.js telemetry
NEXT_TELEMETRY_DISABLED=1

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# CORS allowed origins (production)
# CORS_ORIGINS=https://your-domain.com,https://www.your-domain.com

# Rate limiting configuration
# RATE_LIMIT_MAX=100
# RATE_LIMIT_WINDOW=900000

# Session configuration
# SESSION_MAX_AGE=2592000

# =============================================================================
# DOCKER CONFIGURATION
# =============================================================================

# Docker-specific overrides (used in docker-compose.yml)
# These are set automatically by docker-compose, but can be overridden

# DOCKER_MONGODB_URI=mongodb://mongo:27017/procureflow
# DOCKER_NEXTAUTH_URL=http://localhost:3000

# =============================================================================
# EXAMPLE VALUES FOR QUICK SETUP
# =============================================================================

# Uncomment and use these for quick local development:

# MONGODB_URI=mongodb://localhost:27017/procureflow
# NEXTAUTH_SECRET=dev-secret-key-not-for-production
# NEXTAUTH_URL=http://localhost:3000
# OPENAI_API_KEY=sk-your-actual-openai-key
# NODE_ENV=development
# NEXT_TELEMETRY_DISABLED=1
